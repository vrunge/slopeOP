<!-- 
%\VignetteEngine{knitr::rmarkdown} 
%\VignetteIndexEntry{An Introduction to slopeOP}
--> 

# slopeOP Vignette
### Vincent Runge
#### LaMME, Evry University
### June 13, 2019

> [Introduction](#intro)

> [The slopeOP function](#sf)

> [Options for constraining inference](#options)

> [plot function](#plot)

<a id="intro"></a>

## Introduction

The package `slopeOP` is designed to segment univariate data <img src="/tex/b704a970e46e8418f3ef56718438b122.svg?invert_in_darkmode&sanitize=true" align=middle width=126.38913869999998pt height=24.65753399999998pt/> by a continuous piecewise linear signal with restrictions on starting/ending values for the inferred segments. These values are contained into the finite set of states <img src="/tex/cef39aeb23a61b09d838693a0897fe03.svg?invert_in_darkmode&sanitize=true" align=middle width=11.187179849999989pt height=22.465723500000017pt/>. 


When we write <img src="/tex/dca84180777f523a6d1cb11ceff47536.svg?invert_in_darkmode&sanitize=true" align=middle width=124.85777534999997pt height=14.15524440000002pt/>, the variable <img src="/tex/6f9bad7347b91ceebebd3ad7e6f6f2d1.svg?invert_in_darkmode&sanitize=true" align=middle width=7.7054801999999905pt height=14.15524440000002pt/> goes through all the values of <img src="/tex/cef39aeb23a61b09d838693a0897fe03.svg?invert_in_darkmode&sanitize=true" align=middle width=11.187179849999989pt height=22.465723500000017pt/> from the smallest one to the biggest one. For computational efficiency we recommend to have <img src="/tex/13f705a91487b0bb06669ee7c6c3552f.svg?invert_in_darkmode&sanitize=true" align=middle width=105.80650409999998pt height=22.831056599999986pt/> but this is not mandatory. 

The cost for data <img src="/tex/7d54d6946c15cd803b31e7da5077c813.svg?invert_in_darkmode&sanitize=true" align=middle width=40.78280084999999pt height=14.15524440000002pt/>, <img src="/tex/a7e59809c70c5654d0732669ce4d3cf6.svg?invert_in_darkmode&sanitize=true" align=middle width=36.90056204999999pt height=20.221802699999984pt/>, with linear interpolation from value <img src="/tex/286f7d4815c0996530bda7973b1ec5ea.svg?invert_in_darkmode&sanitize=true" align=middle width=14.25802619999999pt height=14.15524440000002pt/> to value <img src="/tex/97c7f491f7ac1623c0a86b1fb656029b.svg?invert_in_darkmode&sanitize=true" align=middle width=14.25802619999999pt height=14.15524440000002pt/> is given by

<p align="center"><img src="/tex/32da28b15640aa1c521680c305ded2fc.svg?invert_in_darkmode&sanitize=true" align=middle width=401.57801639999997pt height=48.39056475pt/></p>

The value <img src="/tex/286f7d4815c0996530bda7973b1ec5ea.svg?invert_in_darkmode&sanitize=true" align=middle width=14.25802619999999pt height=14.15524440000002pt/> is "unseen" as the cost <img src="/tex/6598c6a71c20e965dba8e739fd65d865.svg?invert_in_darkmode&sanitize=true" align=middle width=70.78262729999999pt height=26.76175259999998pt/> obtained at index <img src="/tex/0fe1677705e987cac4f589ed600aa6b3.svg?invert_in_darkmode&sanitize=true" align=middle width=9.046852649999991pt height=14.15524440000002pt/> is not present in the summation.

Data are generated by the model 

<p align="center"><img src="/tex/8525275768014f9e64d0244f61ab600f.svg?invert_in_darkmode&sanitize=true" align=middle width=481.47380489999995pt height=35.82121785pt/></p>

with <img src="/tex/9e2fef61c286c438282ce2bf9513dd8d.svg?invert_in_darkmode&sanitize=true" align=middle width=239.6036841pt height=21.18721440000001pt/>, <img src="/tex/e5e607c35cb2b5fa02be9a25cbb7733b.svg?invert_in_darkmode&sanitize=true" align=middle width=107.10602924999999pt height=22.465723500000017pt/> and <img src="/tex/5118258da41c2cdc7d0fd96f2955fe02.svg?invert_in_darkmode&sanitize=true" align=middle width=95.95543319999999pt height=26.76175259999998pt/> identically and independently distributed (iid). The optimization problem is then the following:

<p align="center"><img src="/tex/c3f1419da1436d3dcaf4bb12df979464.svg?invert_in_darkmode&sanitize=true" align=middle width=453.2107701pt height=72.48949455pt/></p>

where the states defined inside the cost function yield the continuity constraint between successive segments.

<img src="/tex/99751e94989c68f9be0f6aa442bc80d5.svg?invert_in_darkmode&sanitize=true" align=middle width=40.302373649999986pt height=22.831056599999986pt/> is a penalty parameter, understood as an additional cost when introducing a new segment. 

Notice that the cost can be computed in constant time with the formula 

<p align="center"><img src="/tex/65dc4200c058ac688623e4791c2e8939.svg?invert_in_darkmode&sanitize=true" align=middle width=536.11095285pt height=34.3600389pt/></p>

<p align="center"><img src="/tex/a1d9b5c990cdc52fb8027b2688f7cd9c.svg?invert_in_darkmode&sanitize=true" align=middle width=312.55418204999995pt height=39.887022449999996pt/></p>

where

<p align="center"><img src="/tex/2b92786806bccea954f56077a6b80ab1.svg?invert_in_darkmode&sanitize=true" align=middle width=512.84137905pt height=47.02068525pt/></p>

To address the continuity constraint, we introduce the function <img src="/tex/ae890e198f4a771aa52230b69322c12f.svg?invert_in_darkmode&sanitize=true" align=middle width=74.25482954999998pt height=24.65753399999998pt/> which is the optimal penalized cost up to position <img src="/tex/4f4f4e395762a3af4575de74c019ebb5.svg?invert_in_darkmode&sanitize=true" align=middle width=5.936097749999991pt height=20.221802699999984pt/> with a last infered value equal to <img src="/tex/6c4adbc36120d62b98deef2a20d5d303.svg?invert_in_darkmode&sanitize=true" align=middle width=8.55786029999999pt height=14.15524440000002pt/> (at position t). The idea is then to update a set

<p align="center"><img src="/tex/64b17ac0eaa9a23ba8f6e8beeef8b6b3.svg?invert_in_darkmode&sanitize=true" align=middle width=239.36380874999998pt height=16.438356pt/></p>

at any time step <img src="/tex/985dbad85d61b07e704840368824ee09.svg?invert_in_darkmode&sanitize=true" align=middle width=88.86217889999998pt height=24.65753399999998pt/>. <img src="/tex/6005746712b75a74769ef4baa4d8fae3.svg?invert_in_darkmode&sanitize=true" align=middle width=32.40983954999999pt height=14.15524440000002pt/> and <img src="/tex/c1a3766b77f3cfa5e53205c84f3a7b1b.svg?invert_in_darkmode&sanitize=true" align=middle width=34.21767194999999pt height=14.15524440000002pt/> are the bounds of the interval of possible ending values for the considered data to segment. They can be determined in a preprocessing step.

The new update with continuity constraint takes the form

<p align="center"><img src="/tex/ab4ef0926386dff2055b015b92895c58.svg?invert_in_darkmode&sanitize=true" align=middle width=368.09542769999996pt height=31.6657044pt/></p>


where the presence of the same value <img src="/tex/6dbb78540bd76da3f1625782d42d6d16.svg?invert_in_darkmode&sanitize=true" align=middle width=9.41027339999999pt height=14.15524440000002pt/> in <img src="/tex/e05578c58a4f9e4f1301d4cf24e3234c.svg?invert_in_darkmode&sanitize=true" align=middle width=20.387619449999992pt height=22.465723500000017pt/> and the cost realizes the continuity constraint. At initial step we simply have <img src="/tex/cf8c7572e6ac52e95e69475a2b4281e3.svg?invert_in_darkmode&sanitize=true" align=middle width=86.58177495pt height=24.65753399999998pt/>. 


<a id="sf"></a>

## The slopeOP function

We install the package from Github:


```r
#devtools::install_github("vrunge/slopeOP")
library(slopeOP)
```

We simulate data with the function `slopeData` given the indices for extremal values and in second vector these values to reach for corresponding indices. The last parameter is the standard deviation of a normal standard noise.


```r
data <- slopeData(c(1,100,200,300,500), c(0,1,0,3,2), 1)
```

The changepoint detection is done by using the function `slopeOP`


```r
slopeOP(data, c(0,1,2,3), 10)
```

```
## $changepoints
## [1]   1 101 201 307 500
## 
## parameters
## [1] 0 1 0 3 2
## 
## globalCost
## [1] 496.4254
## 
## attr(,"class")
## [1] "slopeOP"
```

In `slopeOP` function, the parameter `type` is `channel` by default. With type equal to `channel` we use the monotonicity property in optimal cost matrix to reduce time complexity. If it is equal to `pruning` we prune some positions using a theorem taking into account unseen data.

<a id="options"></a>

## Options for constraining inference


Parameter `constraint` can be set to `up` which corresponds to a restriction to nondecreasing vector parameter.


```r
data <- slopeData(c(1,150,200,350,500,750,1000), c(71,73,70,75,77,73,80), 1)
slopeOP(data, 71:80, 5, constraint = "up")
```

```
## changepoints
## [1]    1   63  254  356  828 1000
## 
## parameters
## [1] 71 72 72 75 75 80
## 
## globalCost
## [1] 1768.407
## 
## attr(,"class")
## [1] "slopeOP"
```

With `constraint` equal to `updown` the infered vector is unimodal (with a maximum).


```r
data <- slopeData(c(1,150,200,350,500,750,1000), c(71,73,70,75,78,73,75), 1)
slopeOP(data, 71:80, 5, constraint = "updown")
```

```
## changepoints
## [1]    1  316  317  502  697 1000
## 
## parameters
## [1] 71 73 74 78 74 74
## 
## globalCost
## [1] 1407.936
## 
## attr(,"class")
## [1] "slopeOP"
```

We also can limit the angles between successive segments with `constraint` equal to `smoothing` and the parameter `minAngle` in degree.


```r
data <- slopeData(c(1,30,40,70,100,150,200),c(70,80,70,80,70,80,70),0.5)
slopeOP(data,70:80,5, constraint = "smoothing", minAngle = 170)
```

```
## changepoints
##  [1]   1   7  19  25  28  34  40  46  47  53  62  68  73  79  94 100 103
## [18] 149 154 160 200
## 
## parameters
##  [1] 71 72 76 77 77 76 74 73 73 74 77 78 78 77 72 71 71 79 79 78 70
## 
## globalCost
## [1] 319.9376
## 
## attr(,"class")
## [1] "slopeOP"
```

<a id="plot"></a>

## Plot function


[Back to Top](#top)

